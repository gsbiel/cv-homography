{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_cv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/fukJiceVjaX8Izp47J2v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsbiel/cv-homography/blob/add-dlt/custom_cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsPQOFpI4efc"
      },
      "source": [
        "# **Computer Vision Assignment - 2**\n",
        "\n",
        "Students: \n",
        "- Gabriel Silva Gaspar; \n",
        "- Sara Sampaio Gomes do Nascimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeW--rb-KQDK",
        "outputId": "98a257c9-93a5-43f2-d7b4-36b4a3c3d290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install opencv-python==3.4.2.16\n",
        "!pip install opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7d/5042b668a8ed41d2a80b8c172f5efcd572e3c046c75ae029407e19b7fc68/opencv_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.18.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-3.4.2.16\n",
            "Collecting opencv-contrib-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/f1/66330f4042c4fb3b2d77a159db8e8916d9cdecc29bc8c1f56bc7f8a9bec9/opencv_contrib_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6MB 160kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.18.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-3.4.2.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZhzkRW8IQGr"
      },
      "source": [
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "import imutils\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "MIN_MATCH_COUNT = 10"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wwRdNVanE_A"
      },
      "source": [
        "# ----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "  Essa função recebe duas imagens como argumento e retorna os pontos de \n",
        "  correspondência entre as duas.\n",
        "\"\"\"\n",
        "\n",
        "def get_correspondence_points(img1, img2):\n",
        "\n",
        "  # Initiate SIFT detector\n",
        "  sift = cv.xfeatures2d.SIFT_create()\n",
        "\n",
        "  # find the keypoints and descriptors with SIFT\n",
        "  kp1, des1 = sift.detectAndCompute(img1,None)\n",
        "  kp2, des2 = sift.detectAndCompute(img2,None)\n",
        "  # FLANN parameters\n",
        "  # FLANN stands for Fast Library for Approximate Nearest Neighbors. \n",
        "  # It contains a collection of algorithms optimized for fast nearest neighbor \n",
        "  # search in large datasets and for high dimensional features. \n",
        "  # It works faster than BFMatcher for large datasets.\n",
        "  # The variable index_params specifies the algorithm to be used, its related parameters etc. \n",
        "  # For algorithms like SIFT, SURF etc. you can pass following:\n",
        "  FLANN_INDEX_KDTREE = 1\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "  # The variable search_params specifies the number of times the trees in the index should \n",
        "  # be recursively traversed. Higher values gives better precision, but also takes more time.\n",
        "  #search_params = dict(checks=50)   # or pass empty dictionary\n",
        "  search_params = dict()\n",
        "\n",
        "  flann = cv.FlannBasedMatcher(index_params,search_params)\n",
        "  matches = flann.knnMatch(des1,des2,k=2)\n",
        "\n",
        "  # store all the good matches as per Lowe's ratio test.\n",
        "  good = []\n",
        "  for m,n in matches:\n",
        "      if m.distance < 0.75*n.distance:\n",
        "          good.append(m)\n",
        "\n",
        "  if len(good)>MIN_MATCH_COUNT:\n",
        "      src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "      dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "      M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
        "      matchesMask = mask.ravel().tolist()\n",
        "  else:\n",
        "    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
        "\n",
        "  return {\n",
        "      \"src_pts\":src_pts,\n",
        "      \"dst_pts\":dst_pts\n",
        "  }\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "Essa função formata os pontos de correspondência retornados pela função FLANN \n",
        "para que fiquem como uma matriz de pontos em coordenadas homogêneas.\n",
        "\"\"\"\n",
        "\n",
        "def format_points(points):\n",
        "  flatten_points = np.ravel(points)\n",
        "  number_of_rows = int(len(flatten_points)/2)\n",
        "  formatted_points = flatten_points.reshape(number_of_rows,2)\n",
        "  ones = np.ones(formatted_points.shape[0])\n",
        "  return np.c_[formatted_points,ones]\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "Função que teremos que implementar.\n",
        "M e mask são os dados que ela deve retornar.\n",
        "\"\"\"\n",
        "\n",
        "def findHomography(src_pts, dst_pts):\n",
        "  # Altera formato do numpy array\n",
        "  src = format_points(src_pts)\n",
        "  dst = format_points(dst_pts)\n",
        "\n",
        "  # Obtém as matrizes de normalização dos pontos de cada imagem\n",
        "  normalize_src = get_normalizing_matrix(src)\n",
        "  normalize_dst = get_normalizing_matrix(dst)\n",
        "\n",
        "  # Normaliza os pontos de cada imagem\n",
        "  src = normalize_src.dot(src.transpose()).transpose()\n",
        "  dst = normalize_dst.dot(dst.transpose()).transpose()\n",
        "\n",
        "  A_list = []\n",
        "\n",
        "  for index in range(0,src.shape[0]):\n",
        "    # Para cada par de correspondências, cria a matriz A\n",
        "    a11 = np.array([0, 0, 0])\n",
        "    a12 = -dst[index][2]*src[index]\n",
        "    a13 = -dst[index][1]*src[index]\n",
        "    a21 = -a12\n",
        "    a22 = np.copy(a11)\n",
        "    a23 = -dst[index][0]*src[index]\n",
        "    a1 = np.concatenate((a11, a12, a13), axis=None)\n",
        "    a2 = np.concatenate((a21, a22, a23), axis=None)\n",
        "    A = np.vstack((a1,a2))\n",
        "    # Insere a matriz A em uma lista de matrizes\n",
        "    A_list.append(A)\n",
        "\n",
        "  # Converte a lista de matrizes em um numpy array\n",
        "  A_stack = np.array(A_list)\n",
        "  # Modela a lista de matrizes para se tornar uma pilha de matrizes\n",
        "  A_stack = A_stack.reshape((A_stack.shape[0]*A_stack.shape[1], 9))\n",
        "  \n",
        "  # Decompõe a matriz A usando decomposição SVD\n",
        "  u, s, vh = np.linalg.svd(A_stack, full_matrices=True)\n",
        "  # Formata a solução do algoritmo DLT, ainda normalizada\n",
        "  M_normalized = vh[:,-1].reshape((3,3))\n",
        "  # Desnormaliza a solução do algoritmo DLT\n",
        "  M = np.linalg.inv(normalize_src).dot(M_normalized.dot(normalize_dst))\n",
        "\n",
        "  # Esse array indica se um ponto é um inlier ou outlier.\n",
        "  # Ele deve ser construído a partir do RANSAC\n",
        "  mask = np.array([\n",
        "                   [0],\n",
        "                   [1],\n",
        "                   [1],\n",
        "                   [0]\n",
        "                   # ...\n",
        "  ])\n",
        "  return [M, mask]\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "Função que calcula a matriz, T, de normalização dos pontos de uma imagem\n",
        "\"\"\"\n",
        "\n",
        "def get_normalizing_matrix(points):\n",
        "  # Calcula a soma dos elementos de cada coluna da matriz\n",
        "  column_sums = points.sum(axis=0)\n",
        "  # Cacula os valores médios de u(eixo x) e v(eixo y) da imagem\n",
        "  u_mean_value = float(column_sums[0])/float(points.shape[0])\n",
        "  v_mean_value = float(column_sums[1])/float(points.shape[0])\n",
        "  # Calcula somatório do quadrado das distâncias de cada ponto da imagem com relação ao ponto médio\n",
        "  sum_of_squares = 0\n",
        "  n = points.shape[0]\n",
        "  for index in range(0,n):\n",
        "    u_diff = points[index][0] - u_mean_value\n",
        "    v_diff = points[index][1] - v_mean_value\n",
        "    sum_of_squares += math.sqrt((math.pow(u_diff,2) + math.pow(v_diff,2)))\n",
        "  # Calcula o parâmetro s da matriz de normalização\n",
        "  s = float(math.sqrt(2)*n)/float(sum_of_squares)\n",
        "  # Calcula e retorna a matriz de normalização\n",
        "  return s*np.array([ \n",
        "                     [1, 0, -u_mean_value],  \n",
        "                     [0, 1, -v_mean_value],   \n",
        "                     [0, 0,    float(1)/s]               \n",
        "  ])"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqcFdbCPL_GE",
        "outputId": "cd436b5c-cae2-41ce-a15d-6ef03ce207f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Carrega imagens para testar a função de homografia\n",
        "img1 = cv.imread('comicsStarWars01.jpg',0) # queryImage\n",
        "img2 = cv.imread('comicsStarWars02.jpg',0) # trainImage\n",
        "\n",
        "# Rotaciona a imagem para ficar melhor a visualização na hora de plotar\n",
        "img1 = imutils.rotate_bound(img1,90)\n",
        "img2 = imutils.rotate_bound(img2, 90)\n",
        "\n",
        "# Obtém pontos de correspondência\n",
        "correspondence_points = get_correspondence_points(img1, img2)\n",
        "\n",
        "# Essa é a função que temos que desenvolver!\n",
        "M, mask = findHomography(correspondence_points[\"src_pts\"], correspondence_points[\"dst_pts\"])\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3)\n",
            "[[ 1.33470580e-01 -8.67167227e-01 -4.08530160e+01]\n",
            " [ 3.97437679e-02 -3.47672656e-01 -7.66428106e+01]\n",
            " [ 1.26454670e-04 -3.41661611e-04 -5.51713410e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}