{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_cv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYwBeq0pbAb1nSQhfWDZ4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsbiel/cv-homography/blob/main/custom_cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsPQOFpI4efc"
      },
      "source": [
        "# **Computer Vision Assignment - 2**\n",
        "\n",
        "Students: \n",
        "- Gabriel Silva Gaspar; \n",
        "- Sara Sampaio Gomes do Nascimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeW--rb-KQDK",
        "outputId": "101200d7-6a48-46bf-ae7d-b259ca76a269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install opencv-python==3.4.2.16\n",
        "!pip install opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python==3.4.2.16 in /usr/local/lib/python3.6/dist-packages (3.4.2.16)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.18.5)\n",
            "Requirement already satisfied: opencv-contrib-python==3.4.2.16 in /usr/local/lib/python3.6/dist-packages (3.4.2.16)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZhzkRW8IQGr"
      },
      "source": [
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "import imutils\n",
        "import numpy as np\n",
        "\n",
        "MIN_MATCH_COUNT = 10"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wwRdNVanE_A"
      },
      "source": [
        "# ----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "  Essa função recebe duas imagens como argumento e retorna os pontos de \n",
        "  correspondência entre as duas.\n",
        "\"\"\"\n",
        "\n",
        "def get_correspondence_points(img1, img2):\n",
        "  \n",
        "  # Initiate SIFT detector\n",
        "  sift = cv.xfeatures2d.SIFT_create()\n",
        "\n",
        "  # find the keypoints and descriptors with SIFT\n",
        "  kp1, des1 = sift.detectAndCompute(img1,None)\n",
        "  kp2, des2 = sift.detectAndCompute(img2,None)\n",
        "  # FLANN parameters\n",
        "  # FLANN stands for Fast Library for Approximate Nearest Neighbors. \n",
        "  # It contains a collection of algorithms optimized for fast nearest neighbor \n",
        "  # search in large datasets and for high dimensional features. \n",
        "  # It works faster than BFMatcher for large datasets.\n",
        "  # The variable index_params specifies the algorithm to be used, its related parameters etc. \n",
        "  # For algorithms like SIFT, SURF etc. you can pass following:\n",
        "  FLANN_INDEX_KDTREE = 1\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "  # The variable search_params specifies the number of times the trees in the index should \n",
        "  # be recursively traversed. Higher values gives better precision, but also takes more time.\n",
        "  #search_params = dict(checks=50)   # or pass empty dictionary\n",
        "  search_params = dict()\n",
        "\n",
        "  flann = cv.FlannBasedMatcher(index_params,search_params)\n",
        "  matches = flann.knnMatch(des1,des2,k=2)\n",
        "\n",
        "  # store all the good matches as per Lowe's ratio test.\n",
        "  good = []\n",
        "  for m,n in matches:\n",
        "      if m.distance < 0.75*n.distance:\n",
        "          good.append(m)\n",
        "\n",
        "  if len(good)>MIN_MATCH_COUNT:\n",
        "      src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "      dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "      M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
        "      matchesMask = mask.ravel().tolist()\n",
        "  else:\n",
        "    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
        "\n",
        "  return {\n",
        "      \"src_pts\":src_pts,\n",
        "      \"dst_pts\":dst_pts\n",
        "  }\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "Função que teremos que implementar.\n",
        "M e mask são os dados que ela deve retornar.\n",
        "\"\"\"\n",
        "\n",
        "def findHomography(src_pts, dst_pts):\n",
        "  M = np.array([\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 1],\n",
        "                [0, 0, 1]\n",
        "  ])\n",
        "  mask = np.array([\n",
        "                   [0],\n",
        "                   [1],\n",
        "                   [1],\n",
        "                   [0]\n",
        "                   # ...\n",
        "  ])\n",
        "  return [M, mask]\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqcFdbCPL_GE"
      },
      "source": [
        "# Carrega imagens para testar a função de homografia\n",
        "img1 = cv.imread('comicsStarWars01.jpg',0) # queryImage\n",
        "img2 = cv.imread('comicsStarWars02.jpg',0) # trainImage\n",
        "\n",
        "# Rotaciona a imagem para ficar melhor a visualização na hora de plotar\n",
        "img1 = imutils.rotate_bound(img1,90)\n",
        "img2 = imutils.rotate_bound(img2, 90)\n",
        "\n",
        "# Obtém pontos de correspondência\n",
        "correspondence_points = get_correspondence_points(img1, img2)\n",
        "\n",
        "# Essa é a função que temos que desenvolver!\n",
        "M, mask = findHomography(correspondence_points[\"src_pts\"], correspondence_points[\"dst_pts\"])"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}